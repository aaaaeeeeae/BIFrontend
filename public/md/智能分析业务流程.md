## 智能分析业务流程

1、用户登录

1. 用户输入

   a. 分析目标

   b. 上传原始数据（Excel，且未经处理）

   c. 设置图表类型、图表目的、图表名称等

2. 后端

   a. 校验用户输入是否合法

   b. 成本控制（查询次数、资源等）

3. 把处理后的数据输入给 AI 模型（调用接口），让AI模型为我们提供图表信息、结论文本
4. 图表信息、结论文本在前端进行展示



## AI 分析

1. 如何向AI提词（promopt）

   a. 持续输入、持续优化

   ​	输入内容越少越不准确

   eg：

   ```
   问：
   我有一些数据，请根据我提供的数据来进行数据分析，并给出分析结果，第一行：日期：1日；入库量：100；出库量80；第二行：日期：2日；入库量300；出库量280；第三行：日期：3日；入库量0；出库量：40；
   ```

   由于有很多重复字词，占用token数量是比较多的

​		b. 数据压缩（或内容压缩，比如把很长的内容提取关键词，也可以让AI来实现）

​			由于AI分析的单次输入是有字数限制，需要对原始数据进行压缩

​		eg：

```
我有一些数据，请根据我提供的数据来进行数据分析，并给出分析结果
表头：
	日期；入库量；出库量；
数据：
	1；100；80；
	2；300；280；
	3；0；40；
	
AI压缩：
根据提供的数据，可以将文本压缩为：
1日：入库100，出库80
2日：入库300，出库280
3日：入库0，出库40
```

2. 数据压缩

   采用csv对文件进行压缩：使用开源库[EasyExcel](https://easyexcel.opensource.alibaba.com/)

3. 拼接

   系统预设（你是一个数据分析师......）、压缩数据、分析目标、图表类型做拼接，并加入一些提示词（数据是、请做成xx图......）

```
"你是一个数据分析师和前端开发专家，接下来我会按照以下固定格式给你提供内容：\n" +
"分析需求：\n" + "{数据分析的需求或者目标}\n" +
"原始数据：\n" + "{csv格式的原始数据，用,作为分隔符}\n" +
"请根据这两部分内容，按照以下指定格式生成内容（此外不要输出任何多余的开头、结尾、注释）\n" + "【【【【【\n" + "{前端 Echarts V5 的 option 配置对象js代码，合理地将数据进行可视化，不要生成任何多余的内容，比如注释}\n" + "【【【【【\n" + "{明确的数据分析结论、越详细越好，不要生成多余的注释}";
```

如何生成图表？

AI无法直接生成现成的图表，但AI可以生成图表的代码options -》 利用前端组件库Echarts 在网页进行展示



3种调用AI模型的方式

1、直接通过官网接口

2、调用云服务商提供的，封装后的AI接口



## 优化 prompt

​	a. 指定预设

​		eg：你是一个数据分析师和前端开发专家，

​	b. 指定输入输出格式

​		eg：

​			分析需求：

​			{数据分析的需求或者目标}
​			原始数据：

​			{csv格式的原始数据，用,作为分隔符}

​			请根据这两部分内容，按照以下指定格式生成内容（此外不要输出任何多余的开头、结尾、注释）

​			【【【【【

​			{前端 Echarts V5 的 option 配置对象js代码，合理地将数据进行可视化，不要生成任何多余的内容，比如注释}

​			【【【【【

​			{明确的数据分析结论、越详细越好，不要生成多余的注释}

​	c. 指定一个实例问答，one-shot或者few-shot



## 系统优化

#### 文件校验

Q：用户上传超大文件怎么办，或上传文件不合规范怎么处理？

​	永远不要相信用户输入，一定要校验文件！！！

​		a. 文件大小 --- 目前1mb

​			分片传输，文件超过100mb可以考虑分片，目前也不考虑大文件的分析，如果要实现可以去使用cos对象存储

​		b. 文件后缀

​		c. 文件内容（成本高）

​		d. 文件的合规性（敏感词汇），一般用第三方cos对象存储或者腾讯云图片万象数据审核

A：对用户上传的文件做好校验

​		这个项目中仅仅校验了上传文件的大小、文件的后缀名

#### 数据存储（暂未实现）

目前是把图表的原始数据全部存放到一个chart表的一个字段里，但这么做会有很多问题：

​	a. 上传原始数据量特别大，图表数也很多，查询表就会很慢

​	b. 用户想要查看原始数据，对原始数据进行简单查询、修改，那将读取整个图表数据文件

​	c. 用户还想只看某一个维度，想从一个维度或者部分数据来进行分析，处理起来效果非常低

解决方案：把每个图表的原始数据单独保存为一个新的数据表，而不是存储在一张表的一个字段里，这样每个用户查询的时候不会互相影响，查询性能更好，而且能兼容其他用户需求

#### 用户限流

Q：用户疯狂点击提交？

A：前端可以做防抖处理，但用户也可能疯狂刷量，使用系统是需要消耗成本的，而且一个用户疯狂使用会导致服务器资源被沾满，其他用户无法使用，可以采取以下措施：

​		a. 限制用户调用次数，控制成本

​		b. 单个用户做限流

​			限流阈值应该多少合适？参考正常用户的使用即可

[限流算法](https://juejin.cn/post/6967742960540581918) ：固定窗口限流、滑动窗口限流、漏桶限流、令牌桶限流

解决方案：单机限流 -》 第三方 Guava RateLimiter 库

​					分布式限流 -》 Redission（基于令牌算法），里面内置了限流工具类，可以帮助利用redis来统计

​		这个项目就是依靠 Redission，给每个用户分配一个限流器，仅允许用户每秒最多访问 2 次

#### 并发性、可扩展性

Q：AI生成得很慢，但有很多用户同时提交，给系统造成较大压力，怎么兼顾用户体验和系统可用性？

A：我们想要的结果是点击提交之后，不需要在界面傻等，可以继续提交其他的，需要将流程异步执行。调用的服务处理能力有限，或者接口的处理时长较长时，就该考虑异步化了，将同步改为异步。

标准异步化业务流程

​	1、当用户要进行耗时很长的操作时，点击提交后，不需要在页面等待，而是把这个任务保存到数据库中记录下来

​	2、用户执行任务时

​		a. 任务提交成功

​			程序有多余空闲线程，可以立刻去执行这个任务

​			程序中线程都在繁忙，无法继续处理，那就放到任务队列中

​		b. 任务提交失败

​			拒绝掉任务再也不去执行

​			通过保存到数据库总的记录来看到提交失败的任务，在程序空闲时再捞取执行

​	3、用户可以随时查询任务的执行状态或者在任务执行成功或失败的时候得到通知

​	4、程序从任务队列中取出任务依次执行，每完成一项工作都要修改一下任务的状态

​	5、若执行任务非常复杂，包含多个小任务时，在每执行完一个任务都需要去更新执行状态

本项目优化后的系统业务流程：

​	用户点击提交按钮后，先把图表立刻保存到数据库中（作为一个任务）

​	用户可以在图表管理页面查看所有图表（已生成的、生成中的、生成失败的）的信息和状态

​	用户可以修改生成失败的图表信息，点击重新新生成

这里的异步是通过 本地线程池 来实现，线程池的存在就是管理线程、协调任务的执行过程

如何实现线程池？

​	在Spring中，可以使用 ThreadPoolTaskExecutor 配合@Async注解来实现（不建议）	

​	在java中，可以使用JUC并发编程包中的ThreadPoolExecutor来实现

```java
public ThreadPoolExecutor(int corePoolSize,
                          int maximumPoolSize,
                          long keepAliveTime,
                          TimeUnit unit,
                          BlockingQueue<Runnable> workQueue,
                          ThreadFactory threadFactory
                          RejectedExecutionHandler handler) {
    }
corePoolSize 核心线程数，正常情况下系统能够同时工作的线程数 （正式工）
maximumPoolSize 最大线程数，极限情况下，最多有多少个线程 （正式工+临时工）
keepAliveTime 空闲线程存活时间，释放无用的线程资源 （解雇临时工）
unit 空闲线程存活时间单位，分钟、秒...
workQueue 任务队列，存放给线程执行的任务
threadFactory 线程工程，控制每个线程的生成、线程的属性
RejectedExecutionHandler 拒绝策略，当任务队列满的时候，采取怎样的措施，比如抛异常、不抛异常...
```

如何配置参数？

​	根据实际情况，考虑系统瓶颈

​	一般情况下，任务分为IO密集型和计算密集型两种

​		a. 计算密集型：吃cpu，比如音视频处理、图像处理、数学计算等，一般是设置 corePoolSize 为cpu的核数 + 1

​		b. IO密集型：吃带宽、内存、硬盘的读写资源，corePoolSize 可以设置大一点，一般经验值是 2n，可以以 IO 能力为主。

​	代码里设置的参数为：2，4，100，SECONDS，queue.size = 4,

redission 执行流程：

​	一开始来了1个任务，新创建一个线程1

​	又来了1个任务，新创建一个线程2

​		此时已经达到设置的核心线程数了

​	又来了4个任务，没有线程去执行，就会放到任务队列中，此时任务队列刚好满

​	又来1个任务，核心线程数满了，任务队列满了，但最大线程数没满，则再创建一个线程3（临时工），并且运行的是新加的那个任务7

​	又来1个任务，再创建一个线程4（临时工）	

​	再来一个任务，发现都满了，报错，直接丢弃这个任务

#### 集中控制、应用解耦

目前，任务是放到内存中执行的，可能会丢失，而且线程池是单机限制的，无法集中控制（部署到多台服务器上，每台开2个，n个服务器就是2n个，也超过了服务的能力）

可以采用中间件来实现，常用的中间件有redis、消息队列、Etcd

消息队列

应用场景：在多个不同的系统、应用中实现消息的传递（应用解耦）

模型

​	生产者：producer，类比于快递员，发消息

​	消费者：consumer，类比于取快递的人，读消息

​	消息：message，类比于快递，就是生产者要传输给消费者的数据

​	消息队列：queue

​	生产者不关心你的消费者要不要消费，什么时候消费，只要存储在队列中，工作就完成了

优点：

​	异步处理

​	削峰填谷

​	数据持久化：把消息集中存储到硬盘中，服务器重启不会丢失

​	可拓展性：可以根据需求随时增加或减少节点，继续保持稳定的服务

​	应用解耦：连接各个不同语言、框架开发的系统，让这些系统能够灵活传输读取数据

主流分布式消息队列：activemq、rabbitmq、kafka、rocketmq、pulsar

技术对比：

| 技术名   | 吞吐量 | 时效性     | 可用性 | 可靠性 | 优势                                                     | 应用场景                                                     |
| -------- | ------ | ---------- | ------ | ------ | -------------------------------------------------------- | ------------------------------------------------------------ |
| activemq | w      | 高，ms     | 高     | 高     | 简单易学                                                 | 中小型企业、项目                                             |
| rabbitmq | w      | 极高，微秒 | 高     | 高     | 生态好、时效性高、易学                                   | 绝大多数分布式应用                                           |
| kafka    | 10w    | 高，ms     | 极高   | 极高   | 吞吐量大、可靠性、可用性、强大的数据流处理能力           | 大规模数据处理场景，如构建日志收集系统、实时数据流传输、事件流收集传输 |
| rocketmq | 10w    | 高，ms     | 极高   | 极高   | 吞吐量大、可靠性、可用性、可拓展性                       | 金融、电商等对可靠性要求较高的场景，适合大规模的消息处理     |
| pulsar   | 10w    | 高，ms     | 极高   | 极高   | 可靠性、可用性很高，基于发布订阅模型，新兴，技术架构先进 | 适合大规模、高并发的分布式系统（云原生），适合实时分析、事件流处理、IoT数据处理等 |

rabbitmq

[rabbitmq官方文档](https://www.rabbitmq.com/getstarted.html)

核心机制：

​	1、消息过期机制

​		给每条消息指定一个有效期，一段时间内未被消费者处理就过期了

​	2、消息确认机制

​		为了保证消息成功被消费，消费者收到消息后会给一个反馈：ack（消费成功）、nack（消费失败）、reject（拒绝），如果配置autoack会自动执行ack命令，接收到消息立刻就成功了

​	3、死信队列

​		为了保证消息的可靠性，需要提供一个容错机制，即失败的消息怎么处理

​		死信：过期的消息、拒收的消息、消息队列满了、处理失败的消息的统称

​		死信队列其实就是专门处理死信任务的队列

rabbitmq在项目中的使用：

​	如何在项目中使用rabbitmq？

​		使用官方客户端（兼容性好，换语言成本低，但要自己去处理一些事情，比如不可能一个线程一个channel，需要自己维护管理链接）

​		封装好的客户端，比如 SpringBootRabbitMQ Starter（简单易用，直接配置直接使用，但有学习成本，不够灵活，被框架限制）

​		[官方文档](https://spring.io/guides/gs/messaging-rabbitmq/)

优化项目

​	以前是把任务提交到线程池，然后在线程池提交中编写处理程序的代码，线程池内排队。如果程序中断，任务就会丢失

​	改造后的流程：

​		1、把任务提交改为向消息队列发送消息

​		2、写一个专门接受消息的程序，处理任务

​		3、消息全部集中发到消息队列，日后如果部署了多个后端，都会从同一个地方取任务，也就实现了分布式负载均衡

​		



## 目前系统存在的问题

无 guava Retrying 重试机制

无AI生成错误（AI生成的格式不匹配、有多余的话、生成图表的代码错误等），在后端进行异常处理

无任务超时控制

无反向压力，调用服务状态来选择当前系统的策略，（比如根据AI服务来控制系统的核心线程数）以最大化利用系统资源

图表页面新增一个刷新、定时自动刷新的按钮，保证获取到图表的最新状态（前端轮询）

任务执行成功或失败，给用户发送实时消息通知（webSocket）



## 写代码时遇到的问题

1、安装marked报错

原因：本机安装的版本是node16，最新版本需要node>18，改个合适的版本就好了

![image-20240229154638097](D:\Typora\photos\image-20240229154638097.png)

2、点击分页器，向后端请求当前页面图表相关数据后，图表并没有更新，还是上一页的图表内容

原因：vue的渲染通过key来区分虚拟dom是否更新，我在组件中绑定的key是一个固定值，虽然通过接口传进去了新的数据，但虚拟dom并没有更新，因此视图不会更新

改正：将v-for的key绑定为后端返回的图表的id即可。

3、chatgpt生成的代码有问题：有多余markdown格式导致无法正确转换为option对象、生成的代码本身是错误的（待完成）

关于多余的markdown，在前后端直接做相应的删除处理就行

但chatGPT生成的代码错误问题只能在前端发现，有报错的时候，向后端发起错误请求，让后端重新生成并返回结果就好了

